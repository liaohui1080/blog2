(window.webpackJsonp=window.webpackJsonp||[]).push([[41],{373:function(t,a,e){"use strict";e.r(a);var r=e(19),s=Object(r.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h2",{attrs:{id:"cosyvoice2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#cosyvoice2"}},[t._v("#")]),t._v(" cosyvoice2")]),t._v(" "),a("blockquote",[a("p",[a("a",{attrs:{href:"https://funaudiollm.github.io/cosyvoice2/",target:"_blank",rel:"noopener noreferrer"}},[t._v("cosyvoice2 官网"),a("OutboundLink")],1)])]),t._v(" "),a("p",[t._v("CosyVoice 2.0正式发布！相比1.0版本，新版本语音生成更准确、更稳定、更快速、功能更强大。")]),t._v(" "),a("h4",{attrs:{id:"多种语言"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#多种语言"}},[t._v("#")]),t._v(" 多种语言")]),t._v(" "),a("p",[t._v("支持语言：中文、英文、日语、韩语、中国方言（粤语、四川话、上海话、天津话、武汉话等）\n跨语言和混合语言：支持跨语言和代码切换场景的零样本语音克隆。")]),t._v(" "),a("h4",{attrs:{id:"超低延迟"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#超低延迟"}},[t._v("#")]),t._v(" 超低延迟")]),t._v(" "),a("p",[t._v("双向流支持：CosyVoice 2.0 集成了离线和流建模技术。\n快速首包合成：实现低至 150 毫秒的延迟，同时保持高质量的音频输出。")]),t._v(" "),a("h4",{attrs:{id:"高精度"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#高精度"}},[t._v("#")]),t._v(" 高精度")]),t._v(" "),a("p",[t._v("改进发音：与 CosyVoice 1.0 相比，发音错误减少了 30% 到 50%。\n基准测试成果：在Seed-TTS评估集的硬测试集上取得最低的字符错误率。")]),t._v(" "),a("h4",{attrs:{id:"稳定性强"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#稳定性强"}},[t._v("#")]),t._v(" 稳定性强")]),t._v(" "),a("p",[t._v("音色一致性：确保零样本和跨语言语音合成的可靠语音一致性。\n跨语言合成：与 1.0 版本相比有显著的改进。")]),t._v(" "),a("h4",{attrs:{id:"自然体验"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#自然体验"}},[t._v("#")]),t._v(" 自然体验")]),t._v(" "),a("p",[t._v("增强韵律和音质：改进了合成音频的对齐，将 MOS 评估分数从 5.4 提高到 5.53。\n情感和方言灵活性：现在支持更细致的情感控制和口音调整。")]),t._v(" "),a("h2",{attrs:{id:"chattts"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#chattts"}},[t._v("#")]),t._v(" chattts")]),t._v(" "),a("blockquote",[a("p",[a("a",{attrs:{href:"https://github.com/2noise/ChatTTS/blob/main/docs/cn/README.md",target:"_blank",rel:"noopener noreferrer"}},[t._v("ChatTTS 官网"),a("OutboundLink")],1)])]),t._v(" "),a("blockquote",[a("p",[t._v("对话式 TTS: ChatTTS 针对对话式任务进行了优化，能够实现自然且富有表现力的合成语音。它支持多个说话者，便于生成互动式对话。")])]),t._v(" "),a("blockquote",[a("p",[t._v("精细的控制: 该模型可以预测和控制精细的韵律特征，包括笑声、停顿和插入语。")])]),t._v(" "),a("blockquote",[a("p",[t._v("更好的韵律: ChatTTS 在韵律方面超越了大多数开源 TTS 模型。我们提供预训练模型以支持进一步的研究和开发。")])]),t._v(" "),a("h2",{attrs:{id:"gpt-sovits-webui"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#gpt-sovits-webui"}},[t._v("#")]),t._v(" GPT-SoVITS-WebUI")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://www.yuque.com/baicaigongchang1145haoyuangong/ib3g1e/dkxgpiy9zb96hob4#DsYEN",target:"_blank",rel:"noopener noreferrer"}},[t._v("MAC一键安装包"),a("OutboundLink")],1),t._v(" "),a("a",{attrs:{href:"https://www.yuque.com/baicaigongchang1145haoyuangong",target:"_blank",rel:"noopener noreferrer"}},[t._v("作者官网"),a("OutboundLink")],1)]),t._v(" "),a("h3",{attrs:{id:"文字转语音-可以mac运行的-已经实验成功了"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#文字转语音-可以mac运行的-已经实验成功了"}},[t._v("#")]),t._v(" 文字转语音,可以mac运行的,已经实验成功了")]),t._v(" "),a("p",[t._v("零样本文本到语音（TTS）： 输入 5 秒的声音样本，即刻体验文本到语音转换。")]),t._v(" "),a("p",[t._v("少样本 TTS： 仅需 1 分钟的训练数据即可微调模型，提升声音相似度和真实感。")]),t._v(" "),a("p",[t._v("跨语言支持： 支持与训练数据集不同语言的推理，目前支持英语、日语、韩语、粤语和中文。")]),t._v(" "),a("p",[t._v("WebUI 工具： 集成工具包括声音伴奏分离、自动训练集分割、中文自动语音识别(ASR)和文本标注，协助初学者创建训练数据集和 GPT/SoVITS 模型。")]),t._v(" "),a("h2",{attrs:{id:"realtimestt"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#realtimestt"}},[t._v("#")]),t._v(" RealtimeSTT")]),t._v(" "),a("blockquote",[a("p",[a("a",{attrs:{href:"https://github.com/KoljaB/RealtimeSTT",target:"_blank",rel:"noopener noreferrer"}},[t._v("官网"),a("OutboundLink")],1)])]),t._v(" "),a("p",[t._v("RealtimeSTT 语音转文字\n是开源的实时语音转文本库，专为低延迟应用设计。")]),t._v(" "),a("p",[t._v("有强大的语音活动检测功能，可自动识别说话的开始与结束，通过WebRTCVAD和SileroVAD进行精准检测。")]),t._v(" "),a("p",[t._v("同时支持唤醒词激活，借助PorcupineOpenWakeWord检测特定唤醒词来启动。核心转录功能由Faster Whisper实现，可将语音实时转换为文本，适用于语音助手、实时字幕等场景，为开发者提供了一种高效、易用的语音转文本解决方案，助力打造流畅的语音交互体验。")]),t._v(" "),a("h2",{attrs:{id:"funasr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#funasr"}},[t._v("#")]),t._v(" FunASR")]),t._v(" "),a("blockquote",[a("p",[a("a",{attrs:{href:"https://github.com/modelscope/FunASR",target:"_blank",rel:"noopener noreferrer"}},[t._v("官网"),a("OutboundLink")],1)])]),t._v(" "),a("p",[t._v("FunASR 语音转文字")]),t._v(" "),a("p",[t._v("语音识别（ASR）：支持多种预训练模型的推理和微调，提供高精度和高效能。")]),t._v(" "),a("p",[t._v("语音端点检测（VAD）：自动检测语音片段的开始和结束，提高识别效率。")]),t._v(" "),a("p",[t._v("标点恢复：为识别结果添加标点符号，提升可读性。")]),t._v(" "),a("p",[t._v("语言模型：优化识别结果，适应不同语境。")]),t._v(" "),a("p",[t._v("说话人验证与分离：确认说话人身份，分离多说话人语音。")]),t._v(" "),a("p",[t._v("多人对话语音识别：在复杂语音环境中精准识别。")])])}),[],!1,null,null,null);a.default=s.exports}}]);